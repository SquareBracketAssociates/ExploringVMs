[[[eval=true
Gofer it
	smalltalkhubUser: 'ClementBera' project: '3DaysVM';
	version: 'ConfigurationOf3DaysVM-ClementBEra.3';
load.
(Smalltalk at: #ConfigurationOf3DaysVM) loadBleedingEdge.
Smalltalk snapshot: true andQuit: false.
]]]

! Overview of the Bytecode Compiler

A Bytecode Compiler is a tool that converts the source code of a method or a closure to a representation executable by the virtual machine.

In this part of the book, the reader has to implement 3 successives bytecode compilers for a restrictive Smalltalk (As shown in the following subsection, it is almost a complete Smalltalk System). To proceed to the next sections, the reader has to implement at least the 2 first compilers. Although the last compiler adds interesting concepts, its implementation is optional.

!!! Outline

- The first compiler can only compile methods and is built over 3 sections (sections *@SimpleCompil*, *@VarCompil* and *@MethodCompil*).
- The second one has support for closures, as they were implemented for the ''context'' interpreter in the previous part of the book.
- The last and optional compiler introduces inlined compilation of control flow operations.

!! Overall compiler overview

what a compiler does blabla Source code -> AST -> Bytecode / compiled code

!! Restrictive Smalltalk

The language we will work on from this part of the book to the end of the book is a simple object language. Everything is an object as in Smalltalk or Ruby. Every method call is a virtual call (no static call). In the example we will use a dynamically and strongly typed language, but the logic could also apply to a statically and strongly typed language. The language will use classes with single inheritance, though it is possible to add multiple inheritance if the read is interested.

Smalltalk was taken as a direct inspiration for this language. One can see the language as a restrictive Smalltalk or Ruby. It differs from languages like python because it does not support by default static functions such as ==len== and there won't be any primitive types. I guess you can add those features if you want to once you've finished the basic virtual machine.

If you are familiar with Smalltalk, the language built is a Smalltalk with the specific constraints:
- No cascade and no runtime array are allowed
- Numbered primitives are available but not named primitives
- There are no Class Variable nor Shared Pool nor Pool Dictionnaries, by default those variables are globals.

!! Abstract Syntax Tree proposed

Simple and clean, explain cleaned

!! CompiledCode format

We call ==CompiledCode== the class which instances hold code executable by the virtual machine. The virtual machine built will execute the compiled code using a bytecode interpreter, very similar to the closure context interpreter built in the previous part of the book.

==CompiledCode== instances can represent the executable code of a method or a closure. An example of an instance of ==CompiledCode== is shown on figure *@CompiledCode*, it has 5 fields:
- ""numTemps"": holds a Smi representing the number of temporary variables, including the arguments (an argument is considered as a specific kind of temporary variable).
- ""numArgs"": holds a Smi representing the number of arguments. 
- ""maxStackSize"": holds a Smi representing the maximum size the stack of the function activation need in the worst case.
- ""literals"": refers to an array of values, called ''literals''. A literal can be for example a constant accessed from the compiled code. In the next section we will discuss more about literals.
- ""bytecodes"": refes to a byte array holding the bytecodes that the virtual machine executes to run the method.

+Memory representation of CompiledCode.>file://figures/CompiledCode.pdf|width=75|label=CompiledCode+

% concrete example of a method here !!!!

In the ==bytecodes== byte array, each byte means something different. An object, the encoder, is reponsible of the encoding of instructions into bytecodes. Another object, the instruction stream, is responsible of the decoding of the bytecodes into instructions. The encoder usually holds the specification of its encoding. Here is for example the class comment of the ==RSEncoder== you will use:

[[[eval=true
stream << '[[[' << String cr << RSEncoder comment << String cr << ']]]'
]]]

typically write in hexa...

! Compilation of simple Methods
@SimpleCompil

Compilation of examples 1 to 4.

!! Compiling Special Variables

thisContext, self super

!! Compiling Returns

ret

!! Compiling Methods and Sequences

simple things

!! Compiling Literals

lit

! Compilation of Variable Accesses
@VarCompil

Compilation of method 5 to 10.

!! Variable Scopes and Lookups

+Variable scopes.>file://figures/MethodScopes.pdf|width=35|label=MethodScopes+

+Variable Lookup.>file://figures/VariableLookup.pdf|width=95|label=VariableLookup+

normal variables : building the scopes
Global>>instance>>Temp

!! Compiling Assignments

assign

! Full Method Compiler
@MethodCompil

now compile everything but closures

up to example 13

!! Compiling Message Sends

regular and super sends

!! Compiling Primitives

primitive numbered or 0

! Closure Compiler

up to example 18

!! Compiling Variable Accesses

+Variable scopes.>file://figures/BlockScopes.pdf|width=50|label=BlockScopes+

new scopes for temps 

remote temps

!! Compiling a closure

cl

! Static Optimizations of Control Flow Operations

all examples => up to 24

cant optimize much blabla

!! Inlining Finite Loops

the example of #to:do: & #to:by:do:

!! Inlining Branches

the example of ifTrue:, ifTrue:ifFalse:, ifFalse:ifTrue:, ifFalse:

! What makes a good compiler ?

blabla

!! Handling Compilation error and warnings

example

!! Compilation time

why these 2 are first ?

LLVM -=> fast to compile and good error handling, 10% slower in generated code and Apple moved.

!! Generated code execution time

not much we can do in the bytecode compiler though :(

!! Generated code execution memory footprint

often both later are the same as memory access are the more time consuming operation and there are caches.

! Discussion

blabla

!! Handling the hidden semantics

returns and nil blocks.

!! Temp vectors

compiling for StackInterpreter

no implementation :( in exercise, though you can do it.

!! Static versus runtime optimizations

Aggressive specialization vs memory footprint

!! Optimization: Type prediction

To improve the performance of the execution speed of the compiled code by the virtual machine without adding too many constraints on the system, one can implement a technique invented by Dan Ingalls for early versions of Smalltalk called ""Type prediction"".

The idea is to identify frequently used selectors that are almost always executed on objects of the same type, compile them differently and optimize their execution in the virtual machine.

In Pharo, this is done for most of the arithmetic operations:

[[[eval=true
BytecodeEncoder specialSelectors first: 16 
]]]

Let's take the example of ==1 \+ 2==.

Normally, the compiler should compile it as any message send:
[[[
<16 01> pushLiteral: 1
<16 02> pushLiteral: 2
<24 03 01> send: #+
]]]

If this technique is applied, the compiler will have a list of known selectors that should be compiled differently. Message sends with such selectors will be compiled to specific bytecode instruction instead of the generic message send instructions. Then, the virtual machine execute such specific instruction with specialized code for the selector which is faster.

On the compiler implemented in this part of the book, many bytecodes are free. Bytes between 39 and 255 does not encode anything. To apply the technique of Type prediction for ==\+==, the compiler and virtual machine implementors change their code as follow:

- Bytecode set

The bytecode set is extended to support message sends of specific selectors. On the compiler described in this part of the book, one can use ==100== (==64== in hexadecimal) to encode the message send ==\+==.

- Compiler

The compiler has to compile all the message sends with the selector ==\+== to the new bytecode instead of the generic bytecode for message send.

- Virtual machine

Assuming we are in an interpreter-based virtual machine, the interpreter will decode the sends of ==\+== differently as it is not the same bytecode. As ==\+== is used mainly for addition between Smis, the execution of ==\+== will first check if the 2 operands are Smis. If it is the case, then it tries to perform the primitive operation. If no overflow happened, then the interpreter directly pops the 2 values from the stack and pushes the result back. As most sends of ==\+== are used on addition of 2 Smis with no overflow, most sends of ==\+== are drastically faster. If an overflow happened or one of the operands was not a Smi, then the interpreter falls back on the execution of the regular message send. Even in this case, as the selector is a constant (==\+==) and not a value to fetch in the literal frame of the method, the send is still faster.

- Side effects

The bytecode instruction for ==\+== can be encoded in 1 byte as there is no need to encode the index of the selector in the literal frame nor the number of arguments as it is fixed (1). The literal ==\+== does not need to be put in the literal frame of the compiled code, but instead needs to be directly known by the virtual machine. For a frequently used selector such as ==\+==, this can decrease a lot the memory footprint of the compiled code.

The method ==\+== in SmallInteger has to have the same behavior as the inlined operation for ==\+== in the interpreter and can't be changed without changing the interpreter.

!! Hard Inlining of specific messages

In some cases, the compiler and virtual machine implementors can decide to inline specific selectors all the time. This is the case in Pharo for example for (identityEqual) == \=\= ==.

This has implications:

interrupt points

no override / message send / lookup


