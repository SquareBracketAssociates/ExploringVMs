[[[eval=true
Gofer it
	smalltalkhubUser: 'ClementBera' project: '3DaysVM';
	version: 'ConfigurationOf3DaysVM-ClementBera.1';
load.
(Smalltalk at: #ConfigurationOf3DaysVM) loadBleedingEdge.
Smalltalk snapshot: true andQuit: false.
]]]

! Introduction

This part of the book deals with call stack management, especially when the executed programming language supports closures. 

To master all the concepts exposed, the reader has to implement several interpreters with an increasing level of complexity. An interpreter is a program that executes other programs written in a programming language. All the interpreters are designed to execute code written in a very simple programming language, SmiLang.

Although it is recommended to implement all the interpreters described in this part, the reader has only to understand and implement the context interpreters described in Sections 3 and 6 and read the Sections 2 and 9 to continue reading the book. The Sections 4, 5, 7 and 8 deals with interpreters using a native stack and are not required to understand the next parts of the book.

%todo put real links to sections

!!!! Concepts
Readers will learn the following concepts during this tutorial:

- 	Context interpreter
-	Stack Interpreter
-	Stack page management
-	Closure creation and activation
--	Remote temporary variable access
--	Non- local returns


!!!! Outline

This tutorial is divided in several sections:
#	Description of the SmiLang language
#	Implementation of a simple context interpreter
#	Implementation of a simple stack interpreter
#	Addition of stack page management in to the stack interpreter
#	Introduction of naive closures in to the context interpreter
#	Introduction of real closures in to the stack interpreter
#	Discussion: what are the difference between the Smalltalk model and the SmiLang model


!!!! Thanks
Thanks to Cyril Ferlicot, Vincent Blondeau for the early reviews and runs of the tutorial.


! SmiLang: A Simple Integer Language

During this tutorial, the reader will implement several interpreters of the language SmiLang. “Smi” is the nickname for SmallIntegers in several VM development teams, hence SmiLang is a language that just manipulates Smis. This section describes briefly SmiLang, which is a very simple language. SmiLang has only function activations, function returns, temporary variables, and primitive operations on Smis.

!! SmiLang Basics
SmiLang only manipulates Smis: all the variables values are Smis and are initialized by default to 0.  Functions can only be called using with static calls. Every function has to return a value (no procedures). 


The Smi language has 7 instructions:

[[[eval=true
  SmiCompiler usedInstructions do: [ :each |
	stream 
		<< '# ""'
		<< (each name allButFirst: 3)
		<< '"": '
		<< each comment
		<< String cr ].
]]]

!! SmiLang Examples

[[[eval=true

| exampleSelectors selectorTexts |

exampleSelectors := #(#one #add:to: #example07TempAndCallAndCallArgs).
selectorTexts := {
	#one -> 'zero argument function which returns the constant Smi 1' .
	#add:to: -> '2 arguments function which adds the values of the 2 arguments and returns it' .
	#example07TempAndCallAndCallArgs -> 'zero argument function with two static function calls. It also uses a temporary variable'
	} asDictionary.
	
stream << 'Here are '.
exampleSelectors size printOn: stream.
stream << ' examples that show the whole language:'.

exampleSelectors do: [ :each |
	stream cr.
	stream 
		<< '!!!! Function '
		<< each.
	stream cr.
	stream 
		<< 'Function =='
		<< each
		<< '== is a '
		<< (selectorTexts at: each)
		<< '.'.
	stream cr.
	stream cr.
	stream << 'Source code:'.
	stream cr.
	stream << (SmiExamples>>each) sourceCode asPillarSourceCode.
	stream cr.
	stream << 'Instructions:'.
	stream cr.
	stream << (SmiCompiler new compilePharoMethod: (SmiExamples>>each)) printString asPillarSourceCode. ].
]]]

!!! We are set

The complete SmiLang has been introduced. This language may not be usable for a real application but it is perfect for our exercise which consists of the different implementations of function calls and returns.

! Context Interpreter

A context interpreter is an interpreter which represents the activation of each function by a data structure called context. The call stack is composed of a linked list of contexts.

!! What is a Context ?

A Context is a data structure which represents a function activation. In this section, contexts are instances of the class ==SmiContext==.

A Context holds information such as:
- The values of local variables
- The program counter (also called instruction pointer)
- The function being executed (because the function holds the instruction to be executed)
- The context that activated it (also called caller or sender)

Figure *@context1* shows a given computation state showing the relationships between context, stack, function and instructions in SmiLang.

+Relationships between Context, Stack, Function and Instructions in a context interpreter.>file://figures/context1.pdf|width=75|label=context1+

Let us explain this Figure class by class.

!!!! Context.
- The sender field of the Context references another context, the one which activated it. Such context chain is created during function call: the sender context is a function activation with a call to the context function.
- The program counter field holds 3, which means the next instruction the Interpreter will execute is the third instruction of the function.
- The function field is a reference to the function being activated. A context refers to the function because the function is a holder of instructions to be executed. 
- The stack pointer field holds 6, which means that in the space allocated for this specific context stack, which is in our case 7, only 6 values are currently used and the value at position 6 is the top of the stack.
- Lastly, the context references the stack. The context’s stack values are specific to the function activation and independent from other contexts. The values are unrelated to other function activations.

!!!! Function.
- ==Function name== is useful for debugging purpose.
- ==numArguments== and ==numTemporaries== describe the information mandatory to the execution of the function. They are determined by the compiler.= The interpreter and debugger use these values to figure out, for each value on stack, if they correspond to an argument, a temp or a spilled value.
- ==maxStackSize== . For performance reason, the Context, on creation, allocate for its stack enough space for the maximum size its stack can have. The maximum size that the stack can have is specified in the function by the compiler (see field name max stack size which holds 7 in  Figure *@context1*). 

!!!! Stack.

The stack is associated to a context for a function activation. This stack has not a regular stack API such as ==push:== or ==pop==. It has API such as ==at:== or ==at:put:== that the context uses based on the current stackPointer to do stack operations. For example, ==(stack at: stackPointer)== is the equivalent of ==stack top==.

The stack is composed in order as follow:
- The values of the function arguments.
- The values of the temporary variables.
- The spilled values, which are the values pushed on stack by previously executed instructions.

!! Concrete Example: Activation of function add:to:

Remember ==add:to:== function definition is: 

[[[eval=true
stream << (SmiExamples>>#add:to:) sourceCode asPillarSourceCode.
]]]

This function is invoked in particular by the function ==example07TempAndCallAndCallArgs==. 
[[[eval=true
stream << (SmiExamples>>#example07TempAndCallAndCallArgs) sourceCode asPillarSourceCode.
]]]

In Figure *@context2*, the Context represents the activation of the function ==add:to:== within the function ==example07TempAndCallAndCallArgs==.

The sender field holds the activation of the function ==example07TempAndCallAndCallArgs==. As we can see, the function has a call to the function ==add:to:==.

+Context and collaborators for the ==add:to:== call in ==example07TempAndCallAndCallArgs==.>file://figures/context2.pdf|width=78|label=context2+

The programCounter is 2, which means that 
-  The first instructions ==1| pushTemp 2== has already been executed or is currently being executed.
- The second instruction, ==2| pushTemp 1== is the next instruction to be executed. Note that in most interpreter implementations, the ==pushTemp== instruction works both for arguments and temporary variables depending on the value of the temp index encoded in the instruction. For store, it reads the value to store on the stack but does not change the stack pointer. For push, it pushes the value of the temporary variable on the stack. In this case the instruction is used to access the arguments values.

The function field holds a reference to the function ==add:to:==. This function has 2 arguments, 0 temporary variables and a stack that can go up to 4 slots. It has a list of 4 instructions.

The current stack holds the values of the 2 arguments and the spilled value 2 due to the first instruction ==1| pushTemp 2== that has been executed.


!! Interpretation

""Example 1:"" Interpretation of ==1 + 2==

The figure *@contextInterpretation1* shows the state of a context's stack at each pc during the execution of 1 + 2.

+Stack state at each pc during the interpretation of ==1 \+ 2==.>file://figures/contextInterpretation1.pdf|width=70|label=contextInterpretation1+ 

- ""Step 1"": When the interpretation of 1 + 2 starts, stack pointer is at 0, 2 slots are already allocated on stack for the computation, pc is 1.

- ""Step 2"": First instruction execution (pushSmi 1): the constant 1 is pushed on stack. StackPointer is now 1.

- ""Step 3"": Second instruction execution (pushSmi 2):  the constant 2 is pushed on stack. Stack Pointer is now 2.

- ""Step 4"": Third instruction execution (primitive +):  the two constants are popped from the stack, the interpreter computes the result (by asking the host language or the cpu) , and pushes the result on stack. The stack pointer is now 1. The value at the second stack position is 2 but it should not be reached by execution any more.

""Example 2:"" Interpretation of ==temp1 := 1. temp2 := temp1 + 3.==

+Stack state for the first pcs during the interpretation of ==temp1 := 1. temp2 := temp1 \+ 3==.>file://figures/contextInterpretation2.pdf|width=72|label=contextInterpretation2+

The first steps of the interpretation are drawn in figure *@contextInterpretation2*. Try to draw or imagine the next steps.

!! Calls and Returns

In the two first examples we described the instructions that applied inside a function activation. Now let’s discuss the two interesting instructions, function calls and returns. They require the creation or the termination of a function activation.

!!! Function calls

The call instruction creates a new context, pops the arguments from the top of the stack and copy them to the new context’s stack. It then proceeds execution in the freshly created context. Indeed, remember that prior to the call execution, the argument values are in top of the stack of the current context. Once the call is actually performed, the arguments are the first elements of the stack followed by the temporaries of the new function.

!!! Returns

The returnTop instruction pushes the top of stack of the active context on the top of stack of the sender context. It then terminates the active context and resumes execution in the sender context.

!! Build a Context Interpreter

In this exercise, you will build a context Interpreter.

Open a Pharo 4 image, load the package SmiLang you can find on *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*.

Go to the package tag ==SmiLang>>Context== interpreter. A class SmiContext is given and is a possible implementation of a Context for SmiLang.  A ==SmiContextInterpreter== class skeleton is given, but many methods are not implemented (they only hold ==self shouldBeImplemented==). 

The interpretation starts with a fake Context which holds flags. The Interpreter then calls a function (the public API, ==interpret:==, specified in the public method protocol, precise the function to call). The interpreter keeps interpreting instructions until it returns to the flagged context, which signals the end of the execution. It then returns the value computed.

The SmiContextInterpreterTests have to pass.
We suggest to look at the code and the compiled version of the examples.

Good luck and have fun.

! Simple Stack Interpreter

In this section, one has to build a stack interpreter. Instead of considering contexts as separated objects, this interpreter uses a contiguous memory space where function activations reuse arguments pushed on the stack instead of copying them over the new function activation.

The interpreter is considered as simple as it conceptually holds a single monolithic ""infinite stack"". In subsequent implementation we will deal with limited memory stack using stack pages. 
But let us start by discussing the limits of our first naïve context interpreter.

There are different issues to the Context Interpreter performance-wise:

- Time is wasted when copying the arguments at each function call from the caller context to the freshly created context. If one would design a context interpreter which does not copy the arguments (hence they would stay in the caller context), then a context needs additional far memory reads to access its arguments, which is in practice even slower.
- A second problem is that Contexts are separate data structures and hence can be allocated by the host language, like C, far from each other. This implies that memory reads are spread in the memory and this is problematic for performance (mismatch with cpu caches). 
- Another issue is that hardware-implemented cpu instructions like calls and returns are difficult or even impossible to use directly with contexts when in the future the developer will add a just-in-time compiler.

!! Call Stack

In one sentence, a stack interpreter is a context interpreter where all the contexts have been merged into a single stack called "call stack" or "native stack".

!!! Call stack representation

The figure *@stack1* describes the representation of a native stack.

+Representation of a native stack.>file://figures/stack1.pdf|width=75|label=stack1+

The native stack holds information relative to each context next to each other. Assuming that the stack grows down, the data up to a stack frame is related to the sender of the function activation and the data down is related the function called by the activation. 

!!! Interpreter state

The interpreter, instead of knowing the active context, knows directly the state of the active function activation: 
- the active function
- the pc (program counter) being executed
- the active frame pointer: it points to the beginning of the function activation in the native stack
- the stack pointer, it points to the top of the native stack and the top of active stack frame (they are the same). Values will be pushed and popped there.

!!! Stack frame representation

In the native stack, we call ""stack frame"" a portion of the stack that represents a function activation (it corresponds to a context in the previous interpreter, except that the stack frame size is variable depending on how many values were pushed on stack before the activation of the next stack frame). Except the active stack frame, a stack frame is represented in order as follow:
- ""Temporaries"": Allocated at stack frame creation, this space hold the values of the temporary variables of the activation. The size of this space is known thanks to the ==numTemps== property of the function.
- ""Spilled Values"": These values are pushed on top of the stack for the execution by different instructions. The size of this zone is variable, depending on the current execution state. It has a size of 0 at stack frame activation time. Then, for example, if a ==pushSmi== instruction is performed, it will have a size of 1, as the Smi will be pushed on stack.
- ""Arguments"": When calling a function, the interpreter pushes the arguments of the function called on the stack. On the contrary to the context interpreter, the arguments are never copied. Arguments are accessed in the caller stack frame relatively to the active stack frame frame pointer (this is detailed later in the section).
- ""==Function==, ==pc== and ==frame pointer=="": Once a new function is activated, the interpreter can’t hold anymore the pc, the function and the frame pointer of the previous activation. It needs to hold the information related to the new stack frame created for the function being called. To remember the information, the interpreter pushes on stack the active function, pc and frame pointer. On return, it will set its values with the values on stack. The framePointer holds a reference to the beginning of the previous stack frame. 

!!! Active stack frame

The active stack frame, i.e. the bottom stack frame, is different. The active function, pc and framepointer are directly held by the interpreter (they are not on stack). In practice, this avoids memory reads and writes if the interpreter variables (currentFunction, pc, framePointer) are in registers instead of in memory.

!!! Concrete example: Activation of the function add:to:

The figure *@stack2* describes the same example than for the context interpreter in Section 2. Don’t hesitate to compare both architectures if you don’t understand everything.

[[[eval=true
stream << (SmiExamples>>#add:to:) sourceCode asPillarSourceCode.
]]]

+Example of a native stack.>file://figures/stack2.pdf|width=75|label=stack2+

The interpreter holds:
- A reference to the function being executed, the function ==add:to:==
- The pc of the next instruction to execute, 2
- The frame pointer corresponding to the beginning of the current stack frame for the activation of the method ==add:to:==
- The stack pointer, which is the last value being used on stack and the top of the active stack frame

The active stack frame starts with a framePointer which refers to the framePointer of the previous stack frame, i.e., the beginning of the previous stack frame. For example, in figure *@stack2* the interpreter frame pointer points to slot 9 which refers to the previous stack frame start.

!! Temporary access

We assume that the compiler forbids writing into the function arguments (compilation error). Hence, the store into temporary variable instruction remains simple as it assumes the temp index is the index of a temporary variable. Remember that the temporaries are now stored at the beginning of the stack frame (just after the frame pointer).

The ==pushTemp== instruction is different. Depending on the tempIndex and the value of numArgs in the function, two cases are found:

- ""The tempIndex corresponds to an argument."" Its value is accessed in the caller frame relatively to the active frame pointer. The previous frame has at its end the argument values, its function and its pc. The interpreter needs to substract 3 from the stack pointer to reach the zone in the previous stack frame holding arguments, then substract the number of argument and add the tempIndex to access the correct field, as shown on figure *@tempAccess1*.

+Accessing the value of an argument.>file://figures/tempAccess1.pdf|width=75|label=tempAccess1+

- ""The tempIndex corresponds to a temporary variable."" Hence we can access the value relatively to the framepointer. We need to add the tempIndex to the framePointer and substract the number of arguments as they are stored on the caller frame, as shown on figure *@tempAccess2*.

+Accessing the value of a temporary variable.>file://figures/tempAccess2.pdf|width=75|label=tempAccess2+

!! Call Instruction

The call instruction is different from the context interpreter as one needs to update the interpreter state and create a new stack frame instead of simply creating a new context.

The call instruction works as follow:
- Pushes the pc, the active function and the frame pointer on stack.
- Sets up the stack zone after the new frame pointer with only slots for temporary variables (no slots for arguments as they are accessed from the caller frame). It usually implies to update the stackPointer and set the temporary variable fields to a default value (0 in our case).

!! Return instructions

The return instruction has to set the execution to the previous stack frame execution state. This implies popping the stack up to the previous frame pointer, then popping and restoring the previous active function, frame pointer and pc, and lastly popping the arguments of the function call. In addition, it needs to push the returned result on stack.

!! Build a stack interpreter

In this exercise you will build a Stack Interpreter.

Open a Pharo 4 image, load the package ==SmiLang== you can find on *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*.

Go to the package tag ==SmiLang>>Stack interpreter==. A ==SmiStackInterpreter== class skeleton is given, but many methods are not implemented (they only hold ==self shouldBeImplemented==). 

The interpretation starts with a fake stack frame which holds flags. The Interpreter then calls a function (the public API, ==#interpret:==, specified in the public method protocol, defines the function to call). The interpreter keeps interpreting instructions until it returns to the flagged stack frame, which signals the end of the execution. It then returns the computed value.

The ==SmiStackInterpreterTests== have to pass to proceed to the next section. 

Good luck and have fun !

! Stack pages

!!! Problem

The Stack interpreter previously built is nice but it has a critical flaw. It considers the stack to be infinite. This is not possible as you need to specify to the computer a size to allocate for the stack. This size can’t be too big because if the program uses multiple processes, each process requires a separate stack. 

!!! Solution

A common solution is to split the stack into stack pages of limited size. When the bottom of a stack page is reached, the interpreter switch to a new stack page. The stack pages are created at interpreter start-up and there are of  limited number. Once all the pages are full, different strategies exist depending on the language you want to implement:
- Raise a StackOverflow error.
- Serialize a few stack page to free them, and once a serialized stack page needs to be used again materialize it.

!!! Implementation

The implementation is as follow:
# ""Function Activation"": In addition to what is done in the ==StackInterpreter==, the interpreter estimates the stack frame size based on the max stack size field of the function. If there is not enough room in the stack page for the next stack frame, the interpreter switches to a new stack page.
# ""Return"": In addition to the ==StackInterpreter== behavior, if at the top of a stack page, the interpreter returns to a stack frame in another stack page. The top of a stack page can be marked (for example, the saved pc can be saved as a negative value) so the interpreter knows it has to do a return across stack pages.

!!! Exercise

As an exercise, have the ==SmiStackInterpreterWithStackPagesTests== pass by implementing the ==SmiStackInterpreterWithStackPages==.

!!! Making Calls and Returns across Stack Pages Uncommon

A good ==StackInterpreter== needs to be implemented in a way that returns and calls across stack pages are uncommon because they are slower than regular calls and returns. Typically, in the case of recursive fibonnacci, it could be that most of the sends are done across stack pages and the system become dog slow.

To avoid this problem, a good stack interpreter keeps a reference to the last stack page that overflowed and the number of time it overflowed. Each time a stack page overflows, if it is the last one that overflowed, the number of overflows is incremented by 1, else the reference to the last stack page that overflowed is updated and the number of overflow reset. In pseudo-code, that would mean:

[[[
stackPageOverflow: stackPage
    lastStackPageThatOverflowed = stackPage
        ifTrue: [ numOverflow := numOverflow + 1 ]
        ifFalse: [ 
            lastStackPageThatOverflowed := stackPage.
            numOverflow := 1 ]
]]]

When a new stack page is required, if the current stack page has already overflowed, the interpreter decides to copy a certain number of stack frame to new page to make call and return across stack pages less common. The number of stack frame to copy depends on the number of time the stack page has overflowed and is bounded by a maximum value. This cheap strategy makes calls and returns across stack pages uncommon.

! Naive closures in the Context Interpreter

!! Introduction

In this section, the reader will introduce closures the context interpreter. This section deals with the closure implementation and does not explain what is a closure. If you don't know what is a closure, please read first documentation on the internet about it, such as the chapter ""14. Blocks: a Detailed Analysis"" of the free online book ""Deep into Pharo"".

A closure is an object that references a function and an environment, as represented on figure *@closure*. In this implementation, the function will be anonymous and the environment is the context in which the closure was created. We call the environment refered by a closure the closure’s outer context.

+Closure representation.>file://figures/closure.pdf|width=70|label=closure+

In addition to regular function, closure’s function activation (contexts representing closure activations) have a reference to the closure they activated, as represented on figure *@closureContext*. 

+Context versus Closure Context.>file://figures/closureContext.pdf|width=70|label=closureContext+

If the closure is defined in another closure, then the closure’s outer context is a closure context, which has itself a closure with an outer context. We call the ""outer context chain"" the list of outer context from the closure’s direct outer context to the first context which is not a closure activation. Such an outer context chain is represented on figure *@OuterContextChain*.The last context of the chain is called the closure’s ""home context"". If the closure is not nested in another closure, then the closure outer context is its home context.

+Outer Context chain.>file://figures/OuterContextChain.pdf|width=70|label=OuterContextChain+

!!! Extending the language

To support closures, the syntax of SmiLang is extended with the operator ==[ ]== and the primitive operation ==value==.

!!!! Closure creation 

==[ ]== is used to create a new closure. ==[== mark the beginning and ==]== mark the end of the anonymous fonction held by the closure. 

""Example""

In the following example, the function answers a closure holding the anonymous function answering ==1==. Each execution of the function answers a different closure.

[[[eval=true
stream << (SmiAdditionnalExamples>>#example01Closure) sourceCode asPillarSourceCode.
]]]

!!!! Closure activation

The keyword ==value== represents the primitive operation that activates the closure. In a similar way to the function call, ==value== creates a new context, but the context is a closure's activation and not a simple function activation. Once activated, the closure's anonymous function is executed and its result is returned.

""Example""

In the following example, the function activates the closure holding the anonymous function answering ==1==. The ==value== primitive operation activates the closure, hence the result of the function is ==1==.

[[[eval=true
stream << (SmiAdditionnalExamples>>#example02ClosureActivation) sourceCode asPillarSourceCode.
]]]

!!!! Value of temporary variables

As ==[ ]== answers a closure, it is now possible for temporary variable to hold either a Smi or a closure. 

We will consider that it is the developer responsability to call the primitive ==value== on a closure and not on a Smi.

If ==value== is called on a Smi or if a primitive operation on Smis such as ==+== is called with a closure as operand, the interpreter raises an error and stops executing code. 

In a real system, different solutions exists to avoid having runtime hard errors. For example, a type system could allow the compiler to raise a compilation error if such a type missmatch happens. Alternatively, in dynamically-typed languages like Smalltalk, the language runs specific fall-back routines when a primitive fails to handle such problems.

!!! Extra features of closure activations

On the contrary to regular context representing functions, context representing a closure activation can use the closure’s outer context for two different purposes:
- Remote temporary access
- Non local return

!!!! Remote temporary access

The first feature, present in most language having closures, is the access of remote temporary variables. The closure’s function can access temporary variables that are held not in the current context, but in any of the context in the the closure’s outer context chain. 

Here is an example of a closure accessing a remote temporary variable:

[[[eval=true
stream << (SmiAdditionnalExamples>>#example04ClosureRemoteTemp) sourceCode asPillarSourceCode.
]]]

!!!! Non local return

The second feature, present at least in Ruby in the form of Procedure returns and in Smalltalk, is called non local return. When a closure’s activation performs a non local return, it returns from the closure’s home context instead of the closure’s context sender. To learn more about non local returns, you can read the section ""14.4 Returning from inside a Block"" from the free online book ""Deep into Pharo"".

!! Extending the instruction set

To use closures in the context interpreter, we extend SmiLang with 5 new instructions.

[[[eval=true
  SmiClosureCompiler usedInstructions do: [ :each |
	stream 
		<< '- ""'
		<< (each name allButFirst: 3)
		<< '""'
		<< String cr
		<< each comment
		<< String cr ].
]]]

!! Exercise

In this exercise you will extend your ==ContextInterpreter== with a subclass, ==ClosureContextInterpreter==.

Open a Pharo 4 image, load the package SmiLang-ClosureExtension you can find on *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*.

Go to the package tag ==SmiLang-ClosureExtension>>context== interpreter. A ==SmiClosureContextInterpreter== skeleton is given, but many methods are not implemented (they only hold ==self shouldBeImplemented==). 

The SmiClosureContextInterpreterTests have to pass to proceed to the next section. 

Good luck and have fun !

! Simplified Closures in the Stack Interpreter

In the two next sections you will introduce the closures in the stack interpreter.

The two next sections, especially the next one, are ""considerably"" more complex than the other sections. As explained in the introduction, these sections are optional to understand the overall concepts present in this book.

!! Problems

The naive closure model described in the previous section is nice to understand closure activation but is completely broken in the stack interpreter. The main issue lies with terminated function activations.

A closure has a reference to a function and its outer context. It can happen that a closure outer context is terminated, in which case the closure’s actvation cannot perform a non local return. However, it can still access the terminated outer context temporaries.

In the stack interpreter we have no contexts. The closure still needs to reference its enclosing environment for non local returns and remote temporary access. A naive implementation would be to have the closure referencing its outer stack frame. The problem in this case is that when the outer stack frame execution is terminated, the memory location for the stack frame can be overridden by new activations and it is very difficult to know if it has been overridden or not. It is therefore impossible to know if the reference to the outer stack frame still refers to the stack frame or to other data from the stack.

If the outer stack frame happens to be terminated, we have two issues. 

# ""Remote temporary access"": Firstly, if the closure’s activation tries to access remote temporary variables, the dead outer stack frame may not hold any more the temporary values. In fact, the values may have been overriden by new stack frames.
# ""Non local returns"": Secondly, if the closure’s activation tries to perform a non local return, it has to figure out if the closure home context is dead to raise a BlockCannotReturn exception or not. The problem is that the home’s stack frame may be dead but also overridden with another stack frame. It is impossible in the current state to know if the data at the memory location of the home stack frame corresponds to the home stack frame or something else.

!! Solutions

We identified two problems so we need to describe two solutions. In this section, you will build a restrictive interpreter that cannot handle non local returns. It will implements the solution for remote temporary access, but not the one for non local return. In the next section, you will enhance the interpreter to support non local returns. The Closure representation you will use for the two stack interpreters with closures have a field named ==outerStackFrameWrapper==. You will completely ignore this field in this version of the interpreter (but use it in the next section).

This subsection explains how to deal with remote temporary variables only.

!!! Remote temporary access implementation

If a closure outlives its outer stack frame, the outer stack frame field may have been overridden by new values and we can’t access its temporary variables any more. To solve this problem, the compiler will identify temporary variables that are accessed from multiple stack frames. Such variables values will not be stored on stack, but on an array allocated outside of the stack, also called temp vector, as shown on figure *@tempVector1*. In this implementation, the temp vector will be a Pharo array. 

+Temp vector referenced by a closure and a stack frame.>file://figures/tempVector1.pdf|width=70|label=tempVector1+

When a closure is created, if it needs to access remote temporaries, it keeps a reference to a temp vector in addition to its anonymous function and its outer environment. Specific instructions are added in the language to support access to temporaries in temp vectors, to create temp vectors and to create closures with temp vector. We discuss these instructions in the next subsection.

If a regular function (non closure function) holds an instruction which creates a closure and that the closure access the regulr function temporaries, then the regular function starts with a create temp  vector instruction. This instruction creates the temp vector and pushes it on top of stack. The function then stores the temp vector in a temporary variable slot. Further access in the method to the temporaries accessed from multiple stack frame are done indirectly through the temp vector. 

Upon closure activation, if the closure has a temp vector reference, the temp vector is pushed on stack after the arguments and before the temporary variables. The instruction accessing remote temporary variables will allow the execution to access the temp vector’s values. The instruction holds the index of the tempVector so it can be accessed as a temporary variable and the index of the temporary variable in the temp vector, as show on figure *@tempVectorTempAccess*.

+Access of the temporary 2 in vector at 3.>file://figures/tempVectorTempAccess.pdf|width=70|label=tempVectorTempAccess+

!!! Example

!! Extended instruction set

To use closures in the stack interpreter, we extend SmiLang (the non closure interpreter version) with 4 new instructions:

[[[eval=true
  SmiStackClosureCompiler usedInstructions do: [ :each |
	stream 
		<< '- ""'
		<< (each name allButFirst: 3)
		<< '""'
		<< String cr
		<< each comment
		<< String cr ].
]]]

!! Exercise

In this ultimate exercise you will extend your ==StackInterpreter== with a subclass, ==SimplifiedClosureStackInterpreter==. You will subclass directly the ==StackInterpreter== and not the one with stack pages. It is possible to have a closure stack interpreter with stack pages, but you don’t need to deal with the complexity of both to understand the concepts.

Open a Pharo 4 image, load the package ==SmiLang-StackClosureExtension== you can find on *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*.

Go to the package tag ==SmiLang-StackClosureExtension>>stack interpreter==. A ==SmiSimplifiedClosureStackInterpreter== skeleton is given, but many methods are not implemented (they only hold ==self shouldBeImplemented==). 

The ==SmiSimplifiedClosureStackInterpreterTests== have to pass to proceed to the next section.

Good luck and have fun !

! Real Closures in the Stack Interpreter

In this section we extend the previous interpreter to support non local returns.

The general idea is that we do not want to make normal returns more complex because the execution overhead is too high. For example, if at each return we need to check if there is a closure referencing the frame, the performance overhead is way too big. The implementation of non local return needs to avoid such constraints.

!! Non local return implementation

This is one of the trickiest part of the implementation. Now that remote temporary variables are accessed through a temp vector, the closure needs to keep a reference to its outer stack frame activation only for non local returns.

!!! Stack frame representation

For non local return, we will change our stack frame representation. After the frame pointer and before the references to the temporary variables, we will keep two fields in each stack frame. This implies that accessing temporary variables in this interpreter requires to shift the framePointer by an additionnal 2 for the extra two fields. 

+New stack frame representation.>file://figures/stackRepresentation2.pdf|width=60|label=stackRepresentation2+

!!! Stack frame creation

At stack frame creation time (for example a function call), the stack pointer needs also to be pushed by an additionnal 2 to make room for the two fields. The fields will be used for the potential stack frame wrapper (field 1) and the reference to the closure (field 2).

In addition, if the stack frame represents a closure activation, when creating the stack frame the closure field needs to be set to refer to the closure, else it is set to a specific flag (you can use symbols for flags in your implementation) to mark that the frame is not a closure activation. The interpreter can then easily access the closure of the current activation relatively to the frame pointer (framePointer + 2).

Still at stack frame creation time, the stack frame wrapper field is set to another flag with marks the stack frame as not being wrapped. 

!!! Closure creation

When a closure is created in the stack frame, the stack frame needs to be wrapped (if not already wrapped). For this process one needs to understand what a stack frame wrapper is. A stack frame wrapper is a data structure allocated aside from the stack. It has a single field that refers to the frame pointer location of the stack frame it wraps. Wrapping a stack frame implies the creation of the stack frame wrapper so it refers to the stack frame it wraps and to set the stack frame wrapper field of the stack frame to refer to the stack frame wrapper, as shown on figure *@stackFrameWrapper*.

Instead of keeping a reference to their outer context as in the context interpreter, closures keep a reference to their outer stack frame’s stack frame wrapper.

+Stack Frame (not wrapped) versus Wrapped Stack Frame.>file://figures/stackFrameWrapper.pdf|width=75|label=stackFrameWrapper+

!!! Accessing the wrapper from the stack frame

Each stack frame knows if it is already wrapped by checking its stack frame wrapper field:
- If the value is the flag set at stack frame creation time, then it is not wrapped.
- If the value is not the flag, then it is wrapped and the value of the field is the stack frame wrapper.

!!! Accessing the stack frame from the wrapper

It’s more complex for the stack frame wrapper to access its frame because it needs to know if the stack frame it wraps is still valid. This is a two step operations.

Firstly, it needs to figure out if the frame pointer it holds still references to a frame pointer. If the stack frame has been terminated, it may have been overrided by other frames of different size and the stackFramePointer location may be a random field in another stack frame. To do so, it walks the stack starting at the interpreter’s active frame pointer from a frame pointer to the next one, until it finds a frame pointer matching the stackFramePointer. If it finds a matching frame pointer, then the stack frame wrapper references a stack frame, but it does not know yet if it references the stack frame it wraps or another one. If no matching frame pointer are found, then the stack frame is dead.

Secondly, the stack frame wrapper now knows it references a stack frame. It can then read the stack frame wrapper field of the stack frame. If the field refers to the stack frame wrapper itself, then the stack frame is still live. If it refers the flag or another stack frame wrapper, then the stack frame is dead and has been overridden by another stack frame.

!!! Performing a non local return

As described in the previous subsection, to execute this instruction the interpreter needs to walk up the outer stack frame chain to find the home stack frame. If any outer stack frame relation is broken (a stack frame wrapper does not refer to its stack frame any more), then a BlockCannotReturn exception is raised. Once the home stack frame is found, the execution can return the the home’s sender stack frame, pushing the correct non local value on top of its stack.

!! Exercise

In this last exercise you will extend your ==SimplifiedClosureStackInterpreter== with a subclass, ==RealClosureStackInterpreter==. 

Open a Pharo 4 image, load the package ==SmiLang-StackClosureExtension== you can find on *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*.

Go to the package tag ==SmiLang-StackClosureExtension>>stack interpreter==. A ==SmiRealClosureStackInterpreter== skeleton is given, but many methods are not implemented (they only hold ==self shouldBeImplemented==). 

The ==SmiRealClosureStackInterpreterTests== have to pass to proceed to the next section. This exercise is more difficult than the previous ones the non local returns implementation.

Good luck and have fun !

! Discussion

!! What about Contexts and Stack frames in Smalltalk ?

In Smalltalk, from the language, the programmer has the impression that a context interpreter is running. This is convenient as the programmer can manipulate the contexts as objects. This feature is used for the implementation of the debugger, exceptions and continuations.

In the VM, the interpreter is implemented as a stack interpreter for performance. Stack frames are mapped to contexts on demand.

Assuming the programmer request to read or write one of the following field into a context, whereas the VM only holds an empty proxy to a stack frame, how do you expect the VM to read or write:
- Any of the stack values (arguments, temporaries, spilled values) ?
- The program counter and the function ?
- The sender (tip: to write into the sender field you can abuse calls and returns across stack pages)

!! What about Smalltalk Context and sends compared to SmiLang ?

A Smalltalk send does a lookup to find the method to activate and then activate the method. In SmiLang, there is no lookup as the calls are static, but the function activation in SmiLang is very similar to the Smalltalk method activation. 

About the context, there are one main difference. In Smalltalk, the receiver is for the function activation the equivalent of the first argument. However, the receiver is special as it’s the only variable from which the interpreter can directly access its instance variables and it’s the variable used for the lookup.

You can now look into the ==Context== class in Pharo and verify that you understand what the instance variables correspond to and how they are used. You can also inspect some contexts and verify that you understand their states. Closures are slightly more complex in Pharo than in SmiLang, because there are a few optimisations to decrease their memory footprint and improve their performance. 

!! Correction

In the repository *http://smalltalkhub.com/mc/ClementBera/3DaysVM/main*, one can find a package named SmiLang-Correction. It includes a *possible* implementation for each interpreter. 











